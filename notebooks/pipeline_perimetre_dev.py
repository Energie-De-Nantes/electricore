import marimo

__generated_with = "0.14.17"
app = marimo.App(width="medium")


@app.cell(hide_code=True)
def introduction(mo):
    mo.md(
        r"""
    # üîß Pipeline P√©rim√®tre - Tests et Validation

    Ce notebook permet de tester et valider la fonction **`pipeline_perimetre`** qui constitue l'√©tape 
    fondamentale d'enrichissement de l'historique du p√©rim√®tre.

    ## üéØ Objectifs du pipeline_perimetre

    1. **D√©tection des points de rupture** : Identifier les changements de p√©riodes contractuelles
    2. **Insertion d'√©v√©nements FACTURATION** : Ajouter des √©v√©nements synth√©tiques (1er du mois)
    3. **Enrichissement structurel** : Pr√©parer l'historique pour les calculs aval

    ## üìã Workflow de validation

    1. **Chargement** : Import des donn√©es C15 avec ElectriFlux
    2. **Transformation** : Conversion vers HistoriqueP√©rim√®tre 
    3. **Enrichissement** : Application du pipeline_perimetre
    4. **Comparaison** : Analyse avant/apr√®s enrichissement
    5. **Validation** : V√©rification de la coh√©rence des r√©sultats
    6. **M√©triques** : Calcul des indicateurs de qualit√©

    Suivez les √©tapes ci-dessous pour analyser l'enrichissement de votre historique.
    """
    )
    return


@app.cell
def imports():
    import marimo as mo

    # Standard library
    from pathlib import Path
    import pandas as pd
    import numpy as np

    # ElectriFlux - Extract
    from electriflux.simple_reader import process_flux

    # ElectriCore - Transform
    from electricore.inputs.flux import lire_flux_c15

    # ElectriCore - Process (notre fonction √† tester)
    from electricore.core.pipeline_perimetre import pipeline_perimetre

    # Debugging & utilities
    from icecream import ic

    return Path, lire_flux_c15, mo, pipeline_perimetre, process_flux


@app.cell(hide_code=True)
def configuration_paths(Path, mo):
    # Configuration des chemins de donn√©es
    data_path = Path('~/data/flux_enedis').expanduser()
    c15_path = data_path / 'C15'

    _status_message = mo.md(f"""
    ## üìÅ Configuration des chemins

    - **R√©pertoire principal**: `{data_path}`
    - **Flux C15**: `{c15_path}` {'‚úÖ' if c15_path.exists() else '‚ùå (non trouv√©)'}

    Le pipeline_perimetre ne n√©cessite que les donn√©es C15 (historique du p√©rim√®tre).
    """)

    _status_message
    return (c15_path,)


@app.cell(hide_code=True)
def extract_data(c15_path, mo, process_flux):
    # √âtape 1: Extract - Chargement des donn√©es brutes C15
    raw_c15, extract_success = None, False

    try:
        raw_c15 = process_flux('C15', c15_path)
        _extract_status = mo.md(f"""
        ## üì• **Extract - Donn√©es C15 charg√©es**

        - **C15 (Contrats)**: {len(raw_c15)} lignes, {len(raw_c15.columns)} colonnes ‚úÖ

        Donn√©es brutes pr√™tes pour transformation.
        """)
        extract_success = True
    except Exception as e:
        _extract_status = mo.md(f"‚ùå **Erreur lors du chargement C15**: {str(e)}")

    _extract_status
    return extract_success, raw_c15


@app.cell(hide_code=True)
def transform_data(extract_success, lire_flux_c15, mo, raw_c15):
    # √âtape 2: Transform - Conversion vers HistoriqueP√©rim√®tre
    historique_original, transform_success = None, False

    if extract_success and raw_c15 is not None:
        try:
            # Transformation C15 ‚Üí HistoriqueP√©rim√®tre
            historique_original = lire_flux_c15(raw_c15)

            _transform_status = mo.md(f"""
            ## üîÑ **Transform - HistoriqueP√©rim√®tre cr√©√©**

            - **HistoriqueP√©rim√®tre**: {len(historique_original)} √©v√©nements valid√©s ‚úÖ
            - **PDL uniques**: {historique_original['pdl'].nunique()}
            - **P√©riode couverte**: {historique_original['Date_Evenement'].min().strftime('%Y-%m-%d')} ‚Üí {historique_original['Date_Evenement'].max().strftime('%Y-%m-%d')}

            Les donn√©es respectent le sch√©ma Pandera HistoriqueP√©rim√®tre.
            """)
            transform_success = True
        except Exception as e:
            _transform_status = mo.md(f"‚ùå **Erreur de transformation**: {str(e)}")
    else:
        _transform_status = mo.md("‚è≠Ô∏è √âtape Transform ignor√©e (donn√©es brutes manquantes)")

    _transform_status
    return historique_original, transform_success


@app.cell(hide_code=True)
def inspect_original_historique(historique_original, mo):
    # Inspection de l'historique original
    if historique_original is not None:
        # Compter les √©v√©nements par type
        evenements_par_type = historique_original['Evenement_Declencheur'].value_counts()

        _original_display = mo.vstack([
            mo.md("### üìä Historique Original - Analyse"),
            mo.md(f"""
            **Types d'√©v√©nements pr√©sents:**

            {evenements_par_type.to_string()}

            **√âv√©nements FACTURATION existants:** {evenements_par_type.get('FACTURATION', 0)}
            """),
            mo.md("### üìã √âchantillon des donn√©es"),
            historique_original
        ])
    else:
        _original_display = mo.md("‚ùå Historique original non disponible")

    _original_display
    return


@app.cell(hide_code=True)
def execute_pipeline_perimetre(
    historique_original,
    mo,
    pipeline_perimetre,
    transform_success,
):
    # √âtape 3: Process - Application du pipeline_perimetre
    historique_enrichi, pipeline_success = None, False

    if transform_success and historique_original is not None:
        try:
            # Application du pipeline_perimetre
            historique_enrichi = pipeline_perimetre(historique_original)

            _pipeline_status = mo.md(f"""
            ## ‚öôÔ∏è **Process - Pipeline Commun appliqu√©**

            - **Historique enrichi**: {len(historique_enrichi)} √©v√©nements ‚úÖ
            - **Nouveaux √©v√©nements**: +{len(historique_enrichi) - len(historique_original)}
            - **Colonnes**: {len(historique_enrichi.columns)}

            Pipeline commun ex√©cut√© avec succ√®s !
            """)
            pipeline_success = True
        except Exception as e:
            _pipeline_status = mo.md(f"‚ùå **Erreur pipeline_perimetre**: {str(e)}")
    else:
        _pipeline_status = mo.md("‚è≠Ô∏è Pipeline ignor√© (historique original manquant)")

    _pipeline_status
    return historique_enrichi, pipeline_success


@app.cell
def _(historique_enrichi):
    historique_enrichi
    return


@app.cell
def compare_before_after(
    historique_enrichi,
    historique_original,
    mo,
    pipeline_success,
):
    def _():
        # Comparaison avant/apr√®s enrichissement
        if pipeline_success and historique_original is not None and historique_enrichi is not None:
            # √âv√©nements par type - original
            original_events = historique_original['Evenement_Declencheur'].value_counts()
            enriched_events = historique_enrichi['Evenement_Declencheur'].value_counts()

            # Nouveaux √©v√©nements FACTURATION
            nouveaux_facturation = enriched_events.get('FACTURATION', 0) - original_events.get('FACTURATION', 0)

            # Analyse des nouvelles colonnes
            nouvelles_colonnes = set(historique_enrichi.columns) - set(historique_original.columns)

            _comparison = mo.vstack([
                mo.md("## üîç **Comparaison Avant/Apr√®s Enrichissement**"),
                mo.md(f"""
                ### üìà Impact de l'enrichissement

                - **√âv√©nements ajout√©s**: +{len(historique_enrichi) - len(historique_original)}
                - **Nouveaux √©v√©nements FACTURATION**: +{nouveaux_facturation}
                - **Nouvelles colonnes**: {len(nouvelles_colonnes)}

                ### üìä R√©partition des √©v√©nements

                **Avant enrichissement:**
                {original_events.to_string()}

                **Apr√®s enrichissement:**
                {enriched_events.to_string()}
                """),
                mo.md(f"""
                ### üÜï Nouvelles colonnes ajout√©es

                {', '.join(sorted(nouvelles_colonnes)) if nouvelles_colonnes else 'Aucune nouvelle colonne'}
                """)
            ])
        else:
            _comparison = mo.md("‚è≠Ô∏è Comparaison non disponible")
        return _comparison


    _()
    return


@app.cell(hide_code=True)
def inspect_enriched_historique(historique_enrichi, mo, pipeline_success):
    # Inspection d√©taill√©e de l'historique enrichi
    if pipeline_success and historique_enrichi is not None:
        # Focus sur les nouveaux √©v√©nements FACTURATION
        nouveaux_facturation = historique_enrichi[
            historique_enrichi['Evenement_Declencheur'] == 'FACTURATION'
        ].copy()

        _enriched_display = mo.vstack([
            mo.md("### üîã Historique Enrichi - Nouveaux √©v√©nements FACTURATION"),
            mo.md(f"""
            **Nombre d'√©v√©nements FACTURATION g√©n√©r√©s:** {len(nouveaux_facturation)}
            """),
            nouveaux_facturation.head(10) if len(nouveaux_facturation) > 0 else mo.md("‚ùå Aucun √©v√©nement FACTURATION g√©n√©r√©"),
            mo.md("### üìã √âchantillon complet de l'historique enrichi"),
            historique_enrichi.head(10)
        ])
    else:
        _enriched_display = mo.md("‚ùå Historique enrichi non disponible")

    _enriched_display
    return


@app.cell
def quality_metrics(
    historique_enrichi,
    historique_original,
    mo,
    pipeline_success,
):
    def _():
        # M√©triques de qualit√© et validation
        if pipeline_success and historique_original is not None and historique_enrichi is not None:
            # Statistiques de base
            pdls_originaux = historique_original['pdl'].nunique()
            pdls_enrichis = historique_enrichi['pdl'].nunique()

            # V√©rification de la pr√©servation des PDL
            pdls_preserves = pdls_originaux == pdls_enrichis

            # Chronologie
            dates_originales = (historique_original['Date_Evenement'].min(), historique_original['Date_Evenement'].max())
            dates_enrichies = (historique_enrichi['Date_Evenement'].min(), historique_enrichi['Date_Evenement'].max())

            # √âv√©nements FACTURATION par mois
            facturation_events = historique_enrichi[
                historique_enrichi['Evenement_Declencheur'] == 'FACTURATION'
            ]

            if len(facturation_events) > 0:
                facturation_par_mois = facturation_events.groupby(
                    facturation_events['Date_Evenement'].dt.to_period('M')
                ).size()
                facturation_stats = f"Moyenne: {facturation_par_mois.mean():.1f}, Min: {facturation_par_mois.min()}, Max: {facturation_par_mois.max()}"
            else:
                facturation_stats = "Aucun √©v√©nement FACTURATION"

            _quality_metrics = mo.md(f"""
            ## üìä **M√©triques de Qualit√©**

            ### üéØ Pr√©servation des donn√©es
            - **PDL pr√©serv√©s**: {pdls_preserves} ({'‚úÖ' if pdls_preserves else '‚ùå'})
            - **PDL originaux**: {pdls_originaux}
            - **PDL enrichis**: {pdls_enrichis}

            ### üìÖ Couverture temporelle
            - **P√©riode originale**: {dates_originales[0].strftime('%Y-%m-%d')} ‚Üí {dates_originales[1].strftime('%Y-%m-%d')}
            - **P√©riode enrichie**: {dates_enrichies[0].strftime('%Y-%m-%d')} ‚Üí {dates_enrichies[1].strftime('%Y-%m-%d')}

            ### ‚ö° √âv√©nements FACTURATION g√©n√©r√©s
            - **Total**: {len(facturation_events)}
            - **Par mois**: {facturation_stats}
            - **R√©partition par PDL**: {facturation_events['pdl'].nunique()} PDL couverts
            """)
        else:
            _quality_metrics = mo.md("‚è≠Ô∏è M√©triques non disponibles")
        return _quality_metrics


    _()
    return


@app.cell
def validation_checks(historique_enrichi, mo, pipeline_success):
    # Tests de validation automatis√©s
    if pipeline_success and historique_enrichi is not None:
        validation_results = []

        # Test 1: Pr√©sence d'√©v√©nements FACTURATION
        facturation_count = (historique_enrichi['Evenement_Declencheur'] == 'FACTURATION').sum()
        validation_results.append(f"‚úÖ √âv√©nements FACTURATION g√©n√©r√©s: {facturation_count}" if facturation_count > 0 else "‚ùå Aucun √©v√©nement FACTURATION g√©n√©r√©")

        # Test 2: Dates d'√©v√©nements FACTURATION (1er du mois)
        facturation_dates = historique_enrichi[
            historique_enrichi['Evenement_Declencheur'] == 'FACTURATION'
        ]['Date_Evenement']

        if len(facturation_dates) > 0:
            premiers_du_mois = facturation_dates.dt.day == 1
            pct_premiers_mois = (premiers_du_mois.sum() / len(facturation_dates)) * 100
            validation_results.append(f"‚úÖ √âv√©nements FACTURATION au 1er du mois: {pct_premiers_mois:.1f}%" if pct_premiers_mois > 95 else f"‚ö†Ô∏è √âv√©nements FACTURATION au 1er du mois: {pct_premiers_mois:.1f}% (attendu >95%)")

        # Test 3: Ordre chronologique pr√©serv√©
        dates_ordonnees = historique_enrichi['Date_Evenement'].is_monotonic_increasing
        validation_results.append("‚úÖ Ordre chronologique pr√©serv√©" if dates_ordonnees else "‚ö†Ô∏è Ordre chronologique perturb√©")

        # Test 4: Nouveaux champs ajout√©s
        nouvelles_colonnes = set(historique_enrichi.columns) - {'PDL', 'Date_Evenement', 'Evenement_Declencheur', 'Ref_Situation_Contractuelle', 'Statut_Technique', 'Puissance_Souscrite', 'Type_PDL', 'Categorie_Clientele', 'Statut_PDL', 'Secteur_Activite_PDL', 'Code_Postal'}
        validation_results.append(f"‚úÖ Nouvelles colonnes ajout√©es: {len(nouvelles_colonnes)}" if len(nouvelles_colonnes) > 0 else "‚ö†Ô∏è Aucune nouvelle colonne ajout√©e")

        _validation = mo.vstack([
            mo.md("## ‚úÖ **Tests de Validation Automatis√©s**"),
            mo.md("\n".join([f"- {result}" for result in validation_results]))
        ])
    else:
        _validation = mo.md("‚è≠Ô∏è Validation non disponible")

    _validation
    return


@app.cell(hide_code=True)
def debug_interface(mo):
    # Interface interactive pour le debug
    mo.md("""
    ## üîß **Zone de Debug Interactive**

    Utilisez les widgets ci-dessous pour explorer les donn√©es enrichies en d√©tail.
    """)
    return


@app.cell(hide_code=True)
def pdl_selector_widget(mo):
    # Interface pour s√©lectionner un PDL sp√©cifique √† inspecter
    pdl_input = mo.ui.text(placeholder="Entrez un PDL √† inspecter", label="PDL √† analyser")
    pdl_input
    return (pdl_input,)


@app.cell(hide_code=True)
def pdl_detailed_analysis(historique_enrichi, mo, pdl_input, pipeline_success):
    # Analyse d√©taill√©e d'un PDL sp√©cifique
    if pipeline_success and historique_enrichi is not None and pdl_input.value:
        pdl_data = historique_enrichi[historique_enrichi['pdl'] == pdl_input.value].copy()

        if len(pdl_data) > 0:
            # Trier par date
            pdl_data = pdl_data.sort_values('Date_Evenement')

            # Statistiques pour ce PDL
            total_events = len(pdl_data)
            facturation_events = (pdl_data['Evenement_Declencheur'] == 'FACTURATION').sum()
            periode_couverte = (
                pdl_data['Date_Evenement'].min().strftime('%Y-%m-%d'),
                pdl_data['Date_Evenement'].max().strftime('%Y-%m-%d')
            )

            _pdl_analysis = mo.vstack([
                mo.md(f"### üîç Analyse d√©taill√©e du PDL: **{pdl_input.value}**"),
                mo.md(f"""
                **Statistiques:**
                - Total √©v√©nements: {total_events}
                - √âv√©nements FACTURATION: {facturation_events}
                - P√©riode: {periode_couverte[0]} ‚Üí {periode_couverte[1]}
                """),
                mo.md("**Chronologie compl√®te:**"),
                pdl_data[['Date_Evenement', 'Evenement_Declencheur', 'Ref_Situation_Contractuelle']].reset_index(drop=True)
            ])
        else:
            _pdl_analysis = mo.md(f"‚ùå Aucune donn√©e trouv√©e pour le PDL: {pdl_input.value}")
    else:
        _pdl_analysis = mo.md("üí° S√©lectionnez un PDL ci-dessus pour voir l'analyse d√©taill√©e")

    _pdl_analysis
    return


@app.cell(hide_code=True)
def event_filter_widget(historique_enrichi, mo, pipeline_success):
    # Widget pour filtrer par type d'√©v√©nement
    if pipeline_success and historique_enrichi is not None:
        types_evenements = sorted(historique_enrichi['Evenement_Declencheur'].unique())
        event_filter = mo.ui.multiselect(
            options=types_evenements,
            value=['FACTURATION'] if 'FACTURATION' in types_evenements else types_evenements[:2],
            label="Types d'√©v√©nements √† afficher"
        )
    else:
        event_filter = mo.ui.multiselect(options=[], label="Types d'√©v√©nements (donn√©es non disponibles)")

    event_filter
    return (event_filter,)


@app.cell(hide_code=True)
def filtered_events_analysis(
    event_filter,
    historique_enrichi,
    mo,
    pipeline_success,
):
    # Analyse des √©v√©nements filtr√©s
    if pipeline_success and historique_enrichi is not None and event_filter.value:
        filtered_data = historique_enrichi[
            historique_enrichi['Evenement_Declencheur'].isin(event_filter.value)
        ].copy()

        if len(filtered_data) > 0:
            # Statistiques par type
            stats_par_type = filtered_data['Evenement_Declencheur'].value_counts()

            _filtered_analysis = mo.vstack([
                mo.md(f"### üìà Analyse des √©v√©nements: **{', '.join(event_filter.value)}**"),
                mo.md(f"""
                **R√©partition:**

                {stats_par_type.to_string()}

                **Total √©v√©nements s√©lectionn√©s:** {len(filtered_data)}
                """),
                mo.md("**√âchantillon des donn√©es:**"),
                filtered_data.head(15).reset_index(drop=True)
            ])
        else:
            _filtered_analysis = mo.md("‚ùå Aucun √©v√©nement trouv√© avec les filtres s√©lectionn√©s")
    else:
        _filtered_analysis = mo.md("üí° S√©lectionnez des types d'√©v√©nements pour voir l'analyse")

    _filtered_analysis
    return


@app.cell(hide_code=True)
def development_notes(mo):
    mo.md(
        """
    ## üìù **Notes de D√©veloppement**

    ### üéØ Ce que teste ce notebook

    - **Pipeline commun** : Fonction centrale d'enrichissement de l'historique
    - **Points de rupture** : D√©tection automatique des changements de p√©riodes
    - **√âv√©nements FACTURATION** : Insertion d'√©v√©nements synth√©tiques mensuels
    - **Pr√©servation des donn√©es** : Validation de l'int√©grit√© des donn√©es originales

    ### üîç Points de vigilance

    - Les √©v√©nements FACTURATION doivent √™tre g√©n√©r√©s au 1er de chaque mois
    - L'ordre chronologique doit √™tre pr√©serv√©
    - Aucun PDL ne doit √™tre perdu dans le processus
    - Les r√©f√©rences contractuelles doivent rester coh√©rentes

    ### üöÄ Utilisation pour le debugging

    1. V√©rifiez d'abord les m√©triques de qualit√© globales
    2. Utilisez l'analyse par PDL pour les cas sp√©cifiques
    3. Filtrez par type d'√©v√©nement pour comprendre l'impact
    4. Validez la chronologie des √©v√©nements FACTURATION

    ### üìö Context technique

    - **Source** : Flux C15 Enedis (√©v√©nements contractuels)
    - **Transformation** : HistoriqueP√©rim√®tre (sch√©ma Pandera)
    - **Enrichissement** : pipeline_perimetre() avec d√©tection de points de rupture
    - **Usage aval** : Base pour pipeline_abonnement et pipeline_energie
    """
    )
    return


if __name__ == "__main__":
    app.run()
