import marimo

__generated_with = "0.14.17"
app = marimo.App(width="medium")


@app.cell(hide_code=True)
def introduction(mo):
    mo.md(
        r"""
    # ğŸ”§ Pipeline PÃ©rimÃ¨tre - Tests et Validation

    Ce notebook permet de tester et valider la fonction **`pipeline_perimetre`** qui constitue l'Ã©tape 
    fondamentale d'enrichissement de l'historique du pÃ©rimÃ¨tre.

    ## ğŸ¯ Objectifs du pipeline_perimetre

    1. **DÃ©tection des points de rupture** : Identifier les changements de pÃ©riodes contractuelles
    2. **Insertion d'Ã©vÃ©nements FACTURATION** : Ajouter des Ã©vÃ©nements synthÃ©tiques (1er du mois)
    3. **Enrichissement structurel** : PrÃ©parer l'historique pour les calculs aval

    ## ğŸ“‹ Workflow de validation

    1. **Chargement** : Import des donnÃ©es C15 avec ElectriFlux
    2. **Transformation** : Conversion vers HistoriquePÃ©rimÃ¨tre 
    3. **Enrichissement** : Application du pipeline_perimetre
    4. **Comparaison** : Analyse avant/aprÃ¨s enrichissement
    5. **Validation** : VÃ©rification de la cohÃ©rence des rÃ©sultats
    6. **MÃ©triques** : Calcul des indicateurs de qualitÃ©

    Suivez les Ã©tapes ci-dessous pour analyser l'enrichissement de votre historique.
    """
    )
    return


@app.cell
def imports():
    import marimo as mo

    # Standard library
    from pathlib import Path
    import pandas as pd
    import numpy as np

    # ElectriFlux - Extract
    from electriflux.simple_reader import process_flux

    # ElectriCore - Transform
    from electricore.inputs.flux import lire_flux_c15

    # ElectriCore - Process (notre fonction Ã  tester)
    from electricore.core.pipeline_perimetre import pipeline_perimetre

    # Debugging & utilities
    from icecream import ic

    return Path, lire_flux_c15, mo, pipeline_perimetre, process_flux


@app.cell(hide_code=True)
def configuration_paths(Path, mo):
    # Configuration des chemins de donnÃ©es
    data_path = Path('~/data/flux_enedis').expanduser()
    c15_path = data_path / 'C15'

    _status_message = mo.md(f"""
    ## ğŸ“ Configuration des chemins

    - **RÃ©pertoire principal**: `{data_path}`
    - **Flux C15**: `{c15_path}` {'âœ…' if c15_path.exists() else 'âŒ (non trouvÃ©)'}

    Le pipeline_perimetre ne nÃ©cessite que les donnÃ©es C15 (historique du pÃ©rimÃ¨tre).
    """)

    _status_message
    return (c15_path,)


@app.cell(hide_code=True)
def extract_data(c15_path, mo, process_flux):
    # Ã‰tape 1: Extract - Chargement des donnÃ©es brutes C15
    raw_c15, extract_success = None, False

    try:
        raw_c15 = process_flux('C15', c15_path)
        _extract_status = mo.md(f"""
        ## ğŸ“¥ **Extract - DonnÃ©es C15 chargÃ©es**

        - **C15 (Contrats)**: {len(raw_c15)} lignes, {len(raw_c15.columns)} colonnes âœ…

        DonnÃ©es brutes prÃªtes pour transformation.
        """)
        extract_success = True
    except Exception as e:
        _extract_status = mo.md(f"âŒ **Erreur lors du chargement C15**: {str(e)}")

    _extract_status
    return extract_success, raw_c15


@app.cell(hide_code=True)
def transform_data(extract_success, lire_flux_c15, mo, raw_c15):
    # Ã‰tape 2: Transform - Conversion vers HistoriquePÃ©rimÃ¨tre
    historique_original, transform_success = None, False

    if extract_success and raw_c15 is not None:
        try:
            # Transformation C15 â†’ HistoriquePÃ©rimÃ¨tre
            historique_original = lire_flux_c15(raw_c15)

            _transform_status = mo.md(f"""
            ## ğŸ”„ **Transform - HistoriquePÃ©rimÃ¨tre crÃ©Ã©**

            - **HistoriquePÃ©rimÃ¨tre**: {len(historique_original)} Ã©vÃ©nements validÃ©s âœ…
            - **PDL uniques**: {historique_original['pdl'].nunique()}
            - **PÃ©riode couverte**: {historique_original['Date_Evenement'].min().strftime('%Y-%m-%d')} â†’ {historique_original['Date_Evenement'].max().strftime('%Y-%m-%d')}

            Les donnÃ©es respectent le schÃ©ma Pandera HistoriquePÃ©rimÃ¨tre.
            """)
            transform_success = True
        except Exception as e:
            _transform_status = mo.md(f"âŒ **Erreur de transformation**: {str(e)}")
    else:
        _transform_status = mo.md("â­ï¸ Ã‰tape Transform ignorÃ©e (donnÃ©es brutes manquantes)")

    _transform_status
    return historique_original, transform_success


@app.cell(hide_code=True)
def inspect_original_historique(historique_original, mo):
    # Inspection de l'historique original
    if historique_original is not None:
        # Compter les Ã©vÃ©nements par type
        evenements_par_type = historique_original['Evenement_Declencheur'].value_counts()

        _original_display = mo.vstack([
            mo.md("### ğŸ“Š Historique Original - Analyse"),
            mo.md(f"""
            **Types d'Ã©vÃ©nements prÃ©sents:**

            {evenements_par_type.to_string()}

            **Ã‰vÃ©nements FACTURATION existants:** {evenements_par_type.get('FACTURATION', 0)}
            """),
            mo.md("### ğŸ“‹ Ã‰chantillon des donnÃ©es"),
            historique_original
        ])
    else:
        _original_display = mo.md("âŒ Historique original non disponible")

    _original_display
    return


@app.cell(hide_code=True)
def execute_pipeline_perimetre(
    historique_original,
    mo,
    pipeline_perimetre,
    transform_success,
):
    # Ã‰tape 3: Process - Application du pipeline_perimetre
    historique_enrichi, pipeline_success = None, False

    if transform_success and historique_original is not None:
        try:
            # Application du pipeline_perimetre
            historique_enrichi = pipeline_perimetre(historique_original)

            _pipeline_status = mo.md(f"""
            ## âš™ï¸ **Process - Pipeline Commun appliquÃ©**

            - **Historique enrichi**: {len(historique_enrichi)} Ã©vÃ©nements âœ…
            - **Nouveaux Ã©vÃ©nements**: +{len(historique_enrichi) - len(historique_original)}
            - **Colonnes**: {len(historique_enrichi.columns)}

            Pipeline commun exÃ©cutÃ© avec succÃ¨s !
            """)
            pipeline_success = True
        except Exception as e:
            _pipeline_status = mo.md(f"âŒ **Erreur pipeline_perimetre**: {str(e)}")
    else:
        _pipeline_status = mo.md("â­ï¸ Pipeline ignorÃ© (historique original manquant)")

    _pipeline_status
    return historique_enrichi, pipeline_success


@app.cell
def _(historique_enrichi):
    historique_enrichi
    return


@app.cell
def compare_before_after(
    historique_enrichi,
    historique_original,
    mo,
    pipeline_success,
):
    def _():
        # Comparaison avant/aprÃ¨s enrichissement
        if pipeline_success and historique_original is not None and historique_enrichi is not None:
            # Ã‰vÃ©nements par type - original
            original_events = historique_original['Evenement_Declencheur'].value_counts()
            enriched_events = historique_enrichi['Evenement_Declencheur'].value_counts()

            # Nouveaux Ã©vÃ©nements FACTURATION
            nouveaux_facturation = enriched_events.get('FACTURATION', 0) - original_events.get('FACTURATION', 0)

            # Analyse des nouvelles colonnes
            nouvelles_colonnes = set(historique_enrichi.columns) - set(historique_original.columns)

            _comparison = mo.vstack([
                mo.md("## ğŸ” **Comparaison Avant/AprÃ¨s Enrichissement**"),
                mo.md(f"""
                ### ğŸ“ˆ Impact de l'enrichissement

                - **Ã‰vÃ©nements ajoutÃ©s**: +{len(historique_enrichi) - len(historique_original)}
                - **Nouveaux Ã©vÃ©nements FACTURATION**: +{nouveaux_facturation}
                - **Nouvelles colonnes**: {len(nouvelles_colonnes)}

                ### ğŸ“Š RÃ©partition des Ã©vÃ©nements

                **Avant enrichissement:**
                {original_events.to_string()}

                **AprÃ¨s enrichissement:**
                {enriched_events.to_string()}
                """),
                mo.md(f"""
                ### ğŸ†• Nouvelles colonnes ajoutÃ©es

                {', '.join(sorted(nouvelles_colonnes)) if nouvelles_colonnes else 'Aucune nouvelle colonne'}
                """)
            ])
        else:
            _comparison = mo.md("â­ï¸ Comparaison non disponible")
        return _comparison


    _()
    return


@app.cell(hide_code=True)
def inspect_enriched_historique(historique_enrichi, mo, pipeline_success):
    # Inspection dÃ©taillÃ©e de l'historique enrichi
    if pipeline_success and historique_enrichi is not None:
        # Focus sur les nouveaux Ã©vÃ©nements FACTURATION
        nouveaux_facturation = historique_enrichi[
            historique_enrichi['Evenement_Declencheur'] == 'FACTURATION'
        ].copy()

        _enriched_display = mo.vstack([
            mo.md("### ğŸ”‹ Historique Enrichi - Nouveaux Ã©vÃ©nements FACTURATION"),
            mo.md(f"""
            **Nombre d'Ã©vÃ©nements FACTURATION gÃ©nÃ©rÃ©s:** {len(nouveaux_facturation)}
            """),
            nouveaux_facturation.head(10) if len(nouveaux_facturation) > 0 else mo.md("âŒ Aucun Ã©vÃ©nement FACTURATION gÃ©nÃ©rÃ©"),
            mo.md("### ğŸ“‹ Ã‰chantillon complet de l'historique enrichi"),
            historique_enrichi.head(10)
        ])
    else:
        _enriched_display = mo.md("âŒ Historique enrichi non disponible")

    _enriched_display
    return


@app.cell
def quality_metrics(
    historique_enrichi,
    historique_original,
    mo,
    pipeline_success,
):
    def _():
        # MÃ©triques de qualitÃ© et validation
        if pipeline_success and historique_original is not None and historique_enrichi is not None:
            # Statistiques de base
            pdls_originaux = historique_original['pdl'].nunique()
            pdls_enrichis = historique_enrichi['pdl'].nunique()

            # VÃ©rification de la prÃ©servation des PDL
            pdls_preserves = pdls_originaux == pdls_enrichis

            # Chronologie
            dates_originales = (historique_original['Date_Evenement'].min(), historique_original['Date_Evenement'].max())
            dates_enrichies = (historique_enrichi['Date_Evenement'].min(), historique_enrichi['Date_Evenement'].max())

            # Ã‰vÃ©nements FACTURATION par mois
            facturation_events = historique_enrichi[
                historique_enrichi['Evenement_Declencheur'] == 'FACTURATION'
            ]

            if len(facturation_events) > 0:
                facturation_par_mois = facturation_events.groupby(
                    facturation_events['Date_Evenement'].dt.to_period('M')
                ).size()
                facturation_stats = f"Moyenne: {facturation_par_mois.mean():.1f}, Min: {facturation_par_mois.min()}, Max: {facturation_par_mois.max()}"
            else:
                facturation_stats = "Aucun Ã©vÃ©nement FACTURATION"

            _quality_metrics = mo.md(f"""
            ## ğŸ“Š **MÃ©triques de QualitÃ©**

            ### ğŸ¯ PrÃ©servation des donnÃ©es
            - **PDL prÃ©servÃ©s**: {pdls_preserves} ({'âœ…' if pdls_preserves else 'âŒ'})
            - **PDL originaux**: {pdls_originaux}
            - **PDL enrichis**: {pdls_enrichis}

            ### ğŸ“… Couverture temporelle
            - **PÃ©riode originale**: {dates_originales[0].strftime('%Y-%m-%d')} â†’ {dates_originales[1].strftime('%Y-%m-%d')}
            - **PÃ©riode enrichie**: {dates_enrichies[0].strftime('%Y-%m-%d')} â†’ {dates_enrichies[1].strftime('%Y-%m-%d')}

            ### âš¡ Ã‰vÃ©nements FACTURATION gÃ©nÃ©rÃ©s
            - **Total**: {len(facturation_events)}
            - **Par mois**: {facturation_stats}
            - **RÃ©partition par PDL**: {facturation_events['pdl'].nunique()} PDL couverts
            """)
        else:
            _quality_metrics = mo.md("â­ï¸ MÃ©triques non disponibles")
        return _quality_metrics


    _()
    return


@app.cell
def validation_checks(historique_enrichi, mo, pipeline_success):
    # Tests de validation automatisÃ©s
    if pipeline_success and historique_enrichi is not None:
        validation_results = []

        # Test 1: PrÃ©sence d'Ã©vÃ©nements FACTURATION
        facturation_count = (historique_enrichi['Evenement_Declencheur'] == 'FACTURATION').sum()
        validation_results.append(f"âœ… Ã‰vÃ©nements FACTURATION gÃ©nÃ©rÃ©s: {facturation_count}" if facturation_count > 0 else "âŒ Aucun Ã©vÃ©nement FACTURATION gÃ©nÃ©rÃ©")

        # Test 2: Dates d'Ã©vÃ©nements FACTURATION (1er du mois)
        facturation_dates = historique_enrichi[
            historique_enrichi['Evenement_Declencheur'] == 'FACTURATION'
        ]['Date_Evenement']

        if len(facturation_dates) > 0:
            premiers_du_mois = facturation_dates.dt.day == 1
            pct_premiers_mois = (premiers_du_mois.sum() / len(facturation_dates)) * 100
            validation_results.append(f"âœ… Ã‰vÃ©nements FACTURATION au 1er du mois: {pct_premiers_mois:.1f}%" if pct_premiers_mois > 95 else f"âš ï¸ Ã‰vÃ©nements FACTURATION au 1er du mois: {pct_premiers_mois:.1f}% (attendu >95%)")

        # Test 3: Ordre chronologique prÃ©servÃ©
        dates_ordonnees = historique_enrichi['Date_Evenement'].is_monotonic_increasing
        validation_results.append("âœ… Ordre chronologique prÃ©servÃ©" if dates_ordonnees else "âš ï¸ Ordre chronologique perturbÃ©")

        # Test 4: Nouveaux champs ajoutÃ©s
        nouvelles_colonnes = set(historique_enrichi.columns) - {'PDL', 'Date_Evenement', 'Evenement_Declencheur', 'Ref_Situation_Contractuelle', 'Statut_Technique', 'Puissance_Souscrite', 'Type_PDL', 'Categorie_Clientele', 'Statut_PDL', 'Secteur_Activite_PDL', 'Code_Postal'}
        validation_results.append(f"âœ… Nouvelles colonnes ajoutÃ©es: {len(nouvelles_colonnes)}" if len(nouvelles_colonnes) > 0 else "âš ï¸ Aucune nouvelle colonne ajoutÃ©e")

        _validation = mo.vstack([
            mo.md("## âœ… **Tests de Validation AutomatisÃ©s**"),
            mo.md("\n".join([f"- {result}" for result in validation_results]))
        ])
    else:
        _validation = mo.md("â­ï¸ Validation non disponible")

    _validation
    return


@app.cell(hide_code=True)
def debug_interface(mo):
    # Interface interactive pour le debug
    mo.md("""
    ## ğŸ”§ **Zone de Debug Interactive**

    Utilisez les widgets ci-dessous pour explorer les donnÃ©es enrichies en dÃ©tail.
    """)
    return


@app.cell(hide_code=True)
def pdl_selector_widget(mo):
    # Interface pour sÃ©lectionner un PDL spÃ©cifique Ã  inspecter
    pdl_input = mo.ui.text(placeholder="Entrez un PDL Ã  inspecter", label="PDL Ã  analyser")
    pdl_input
    return (pdl_input,)


@app.cell(hide_code=True)
def pdl_detailed_analysis(historique_enrichi, mo, pdl_input, pipeline_success):
    # Analyse dÃ©taillÃ©e d'un PDL spÃ©cifique
    if pipeline_success and historique_enrichi is not None and pdl_input.value:
        pdl_data = historique_enrichi[historique_enrichi['pdl'] == pdl_input.value].copy()

        if len(pdl_data) > 0:
            # Trier par date
            pdl_data = pdl_data.sort_values('Date_Evenement')

            # Statistiques pour ce PDL
            total_events = len(pdl_data)
            facturation_events = (pdl_data['Evenement_Declencheur'] == 'FACTURATION').sum()
            periode_couverte = (
                pdl_data['Date_Evenement'].min().strftime('%Y-%m-%d'),
                pdl_data['Date_Evenement'].max().strftime('%Y-%m-%d')
            )

            _pdl_analysis = mo.vstack([
                mo.md(f"### ğŸ” Analyse dÃ©taillÃ©e du PDL: **{pdl_input.value}**"),
                mo.md(f"""
                **Statistiques:**
                - Total Ã©vÃ©nements: {total_events}
                - Ã‰vÃ©nements FACTURATION: {facturation_events}
                - PÃ©riode: {periode_couverte[0]} â†’ {periode_couverte[1]}
                """),
                mo.md("**Chronologie complÃ¨te:**"),
                pdl_data[['Date_Evenement', 'Evenement_Declencheur', 'Ref_Situation_Contractuelle']].reset_index(drop=True)
            ])
        else:
            _pdl_analysis = mo.md(f"âŒ Aucune donnÃ©e trouvÃ©e pour le PDL: {pdl_input.value}")
    else:
        _pdl_analysis = mo.md("ğŸ’¡ SÃ©lectionnez un PDL ci-dessus pour voir l'analyse dÃ©taillÃ©e")

    _pdl_analysis
    return


@app.cell(hide_code=True)
def event_filter_widget(historique_enrichi, mo, pipeline_success):
    # Widget pour filtrer par type d'Ã©vÃ©nement
    if pipeline_success and historique_enrichi is not None:
        types_evenements = sorted(historique_enrichi['Evenement_Declencheur'].unique())
        event_filter = mo.ui.multiselect(
            options=types_evenements,
            value=['FACTURATION'] if 'FACTURATION' in types_evenements else types_evenements[:2],
            label="Types d'Ã©vÃ©nements Ã  afficher"
        )
    else:
        event_filter = mo.ui.multiselect(options=[], label="Types d'Ã©vÃ©nements (donnÃ©es non disponibles)")

    event_filter
    return (event_filter,)


@app.cell(hide_code=True)
def filtered_events_analysis(
    event_filter,
    historique_enrichi,
    mo,
    pipeline_success,
):
    # Analyse des Ã©vÃ©nements filtrÃ©s
    if pipeline_success and historique_enrichi is not None and event_filter.value:
        filtered_data = historique_enrichi[
            historique_enrichi['Evenement_Declencheur'].isin(event_filter.value)
        ].copy()

        if len(filtered_data) > 0:
            # Statistiques par type
            stats_par_type = filtered_data['Evenement_Declencheur'].value_counts()

            _filtered_analysis = mo.vstack([
                mo.md(f"### ğŸ“ˆ Analyse des Ã©vÃ©nements: **{', '.join(event_filter.value)}**"),
                mo.md(f"""
                **RÃ©partition:**

                {stats_par_type.to_string()}

                **Total Ã©vÃ©nements sÃ©lectionnÃ©s:** {len(filtered_data)}
                """),
                mo.md("**Ã‰chantillon des donnÃ©es:**"),
                filtered_data.head(15).reset_index(drop=True)
            ])
        else:
            _filtered_analysis = mo.md("âŒ Aucun Ã©vÃ©nement trouvÃ© avec les filtres sÃ©lectionnÃ©s")
    else:
        _filtered_analysis = mo.md("ğŸ’¡ SÃ©lectionnez des types d'Ã©vÃ©nements pour voir l'analyse")

    _filtered_analysis
    return


@app.cell(hide_code=True)
def development_notes(mo):
    mo.md(
        """
    ## ğŸ“ **Notes de DÃ©veloppement**

    ### ğŸ¯ Ce que teste ce notebook

    - **Pipeline commun** : Fonction centrale d'enrichissement de l'historique
    - **Points de rupture** : DÃ©tection automatique des changements de pÃ©riodes
    - **Ã‰vÃ©nements FACTURATION** : Insertion d'Ã©vÃ©nements synthÃ©tiques mensuels
    - **PrÃ©servation des donnÃ©es** : Validation de l'intÃ©gritÃ© des donnÃ©es originales

    ### ğŸ” Points de vigilance

    - Les Ã©vÃ©nements FACTURATION doivent Ãªtre gÃ©nÃ©rÃ©s au 1er de chaque mois
    - L'ordre chronologique doit Ãªtre prÃ©servÃ©
    - Aucun PDL ne doit Ãªtre perdu dans le processus
    - Les rÃ©fÃ©rences contractuelles doivent rester cohÃ©rentes

    ### ğŸš€ Utilisation pour le debugging

    1. VÃ©rifiez d'abord les mÃ©triques de qualitÃ© globales
    2. Utilisez l'analyse par PDL pour les cas spÃ©cifiques
    3. Filtrez par type d'Ã©vÃ©nement pour comprendre l'impact
    4. Validez la chronologie des Ã©vÃ©nements FACTURATION

    ### ğŸ“š Context technique

    - **Source** : Flux C15 Enedis (Ã©vÃ©nements contractuels)
    - **Transformation** : HistoriquePÃ©rimÃ¨tre (schÃ©ma Pandera)
    - **Enrichissement** : pipeline_perimetre() avec dÃ©tection de points de rupture
    - **Usage aval** : Base pour pipeline_abonnement et pipeline_energie
    """
    )
    return


if __name__ == "__main__":
    app.run()
