import pandera.pandas as pa
import pandas as pd
import numpy as np
from toolz import curry

from pandera.typing import DataFrame
from electricore.core.p√©rim√®tre import (
    HistoriqueP√©rim√®tre, SituationP√©rim√®tre, ModificationContractuelleImpactante,
    extraire_situation, extraire_p√©riode,
    extraite_relev√©s_entr√©es, extraite_relev√©s_sorties
)
from electricore.core.relev√©s import Relev√©Index, interroger_relev√©s
from electricore.core.√©nergies.mod√®les import BaseCalculEnergies, PeriodeEnergie

from icecream import ic

def pr√©parer_base_√©nergies(
    historique: DataFrame[HistoriqueP√©rim√®tre], deb: pd.Timestamp, fin: pd.Timestamp
) -> DataFrame[BaseCalculEnergies]:
    """
    üèóÔ∏è Pr√©pare la base des √©nergies en identifiant les entr√©es, sorties et MCT dans la p√©riode.

    Args:
        historique (DataFrame[HistoriqueP√©rim√®tre]): Historique des situations contractuelles.
        deb (pd.Timestamp): D√©but de la p√©riode de calcul des √©nergies.
        fin (pd.Timestamp): Fin de la p√©riode de calcul des √©nergies.

    Returns:
        DataFrame[SituationP√©rim√®tre]: Situation contractuelle enrichie pour le calcul des √©nergies.
    """
    colonnes_meta_releve = ['Unit√©', 'Pr√©cision', 'Source']
    colonnes_releve = ['Id_Calendrier_Distributeur', 'Date_Releve', 'Nature_Index', 'HP', 'HC', 'HCH', 'HPH', 'HPB', 'HCB', 'BASE']



    # 1) On r√©cup√©re la situation du p√©rim√®tre telle qu'elle √©tait √† la date de fin
    situation = extraire_situation(fin, historique)

    # 2) On filtre pour n'avoir que les PDLs en service, ou dont le service c'est termin√© dans la p√©riode.
    # (car pour les autres, aka termin√©s avant la p√©riode, il n'y a rien a calculer pour la p√©riode)
    _masque = (situation['Etat_Contractuel'] == 'EN SERVICE') | (
        (situation['Etat_Contractuel'] == 'RESILIE') & (situation['Date_Evenement'] >= deb)
    )
    # Ajouter ici des colonnes supp si besoin de l'info plus loin
    colonnes_√©venement = ['Ref_Situation_Contractuelle', 
                          'pdl', 
                          'Formule_Tarifaire_Acheminement', 
                          'Puissance_Souscrite',
                          'Type_Compteur', 'Num_Compteur', 'Num_Depannage']
    base = (
        situation[_masque]
        .drop(columns=[col for col in situation if col not in colonnes_√©venement])
        .sort_values(by="Ref_Situation_Contractuelle")
        .copy()
    )

    # 3) On interroge le p√©rim√®tre sur les √©ventuelles entr√©es et sorties, et on r√©cup√©re les relev√©s d'index associ√©s.
    p√©riode: DataFrame[HistoriqueP√©rim√®tre] = extraire_p√©riode(deb, fin, historique)

    entr√©es: DataFrame[Relev√©Index] = (
        extraite_relev√©s_entr√©es(p√©riode)
        .set_index('Ref_Situation_Contractuelle')
        .drop(columns=['pdl'])
        .add_suffix('_deb')
        .assign(Entree=True)
    )
    sorties: DataFrame[Relev√©Index] = (
        extraite_relev√©s_sorties(p√©riode)
        .set_index('Ref_Situation_Contractuelle')
        .drop(columns=['pdl'])
        .add_suffix('_fin')
        .assign(Sortie=True)
    )

    # On les fusionne dans la base
    base = (
        base
        .merge(entr√©es, how='left', left_on='Ref_Situation_Contractuelle', right_index=True)
        .merge(sorties, how='left', left_on='Ref_Situation_Contractuelle', right_index=True)
        .fillna({'Entree': False, 'Sortie': False})
        .infer_objects(copy=False)  # Explicitly infer proper dtypes after fillna
    )

    return base

# @pa.check_types
def d√©couper_p√©riodes(
    base_√©nergies: DataFrame[BaseCalculEnergies],
    modifications: DataFrame[ModificationContractuelleImpactante]
) -> DataFrame[BaseCalculEnergies]:
    """
    üìå D√©coupe la base de calcul d'√©nergies en sous-p√©riodes calculables.

    Cette fonction segmente les p√©riodes impact√©es par des modifications contractuelles (MCT)
    en sous-p√©riodes homog√®nes, pr√™tes pour les calculs d‚Äô√©nergies.

    - Ajoute des points de d√©coupage √† chaque MCT.
    - G√©n√®re des p√©riodes couvrantes et calculables avec les valeurs mises √† jour.

    üöÄ R√©sultat : Des p√©riodes propres et exploitables pour le calcul des √©nergies.
    """

    # 1Ô∏è‚É£ **S√©parer les p√©riodes impact√©es et non impact√©es**
    impact√©es = base_√©nergies[
        base_√©nergies["Ref_Situation_Contractuelle"].isin(modifications["Ref_Situation_Contractuelle"])
    ]
    non_impact√©es = base_√©nergies[
        ~base_√©nergies["Ref_Situation_Contractuelle"].isin(modifications["Ref_Situation_Contractuelle"])
    ]

    # 2Ô∏è‚É£ **G√©n√©rer les sous-p√©riodes pour les lignes impact√©es**
    all_periods = []

    for ref_situation, modifs in modifications.groupby("Ref_Situation_Contractuelle"):
        # Trier les modifications chronologiquement
        modifs = modifs.sort_values(by="Date_Evenement")

        # R√©cup√©rer la ligne initiale
        base_ligne = impact√©es[impact√©es["Ref_Situation_Contractuelle"] == ref_situation].iloc[0].copy()

        # Initialisation des dates de d√©coupage
        dates_coupure = [base_ligne["Date_Releve_deb"]] + \
                        modifs["Date_Evenement"].tolist() + \
                        [base_ligne["Date_Releve_fin"]]
        dates_coupure = sorted(set(dates_coupure))

        # 3Ô∏è‚É£ **Cr√©er une ligne par sous-p√©riode**
        for i in range(len(dates_coupure) - 1):
            periode = base_ligne.copy()
            periode["Date_D√©but"] = dates_coupure[i]
            periode["Date_Fin"] = dates_coupure[i + 1]

            # Appliquer la modification contractuelle si elle intervient √† cette date
            modif_courante = modifs[modifs["Date_Evenement"] == dates_coupure[i]]
            if not modif_courante.empty:
                modif_courante = modif_courante.iloc[0]
                periode["Puissance_Souscrite"] = modif_courante["Avant_Puissance_Souscrite"]
                periode["Formule_Tarifaire_Acheminement"] = modif_courante["Avant_Formule_Tarifaire_Acheminement"]

            all_periods.append(periode)
    return all_periods

    # 4Ô∏è‚É£ **Concat√©ner les p√©riodes impact√©es + les non impact√©es**
    base_decoup√©e = pd.concat([non_impact√©es] + all_periods, ignore_index=True)

    return base_decoup√©e

def ajouter_relev√©s(
    base: DataFrame[BaseCalculEnergies], 
    relev√©s: DataFrame[Relev√©Index],
    suffixe: str = "_deb"  # Valeur par d√©faut "_deb", peut √™tre "_fin"
) -> DataFrame[BaseCalculEnergies]:
    """
    üîÑ Ajoute les relev√©s manquants dans la base de calcul des √©nergies.

    Args:
        base (DataFrame[BaseCalculEnergies]): Base existante des calculs d'√©nergie.
        relev√©s (DataFrame[Relev√©Index]): Relev√©s d'index disponibles.
        suffixe (str, optional): Suffixe qui identifie s'il s'agit de relev√©s de d√©but ("_deb") 
                                ou de fin ("_fin"). Par d√©faut "_deb".

    Returns:
        DataFrame[BaseCalculEnergies]: Base mise √† jour avec les relev√©s ajout√©s.
    """
    # Dynamiquement construire les noms de colonnes bas√©s sur le suffixe
    col_date_releve = f"Date_Releve{suffixe}"
    col_source = f"Source{suffixe}"
    
    # üè∑Ô∏è Extraire les paires (Date_Releve, pdl) manquantes dans la base
    requ√™tes_manquantes = (
        base
        .loc[base[col_source].isna(), [col_date_releve, "pdl"]]
        .rename(columns={col_date_releve: 'Date_Releve'})
        .drop_duplicates()
    )
    if requ√™tes_manquantes.empty:
        return base  # ‚úÖ Rien √† ajouter, on retourne la base inchang√©e.
    
    # üîç R√©cup√©ration des relev√©s manquants
    relev√©s_trouv√©s = (
        interroger_relev√©s(requ√™tes_manquantes, relev√©s)
        .add_suffix(suffixe)
        .rename(columns={f'pdl{suffixe}': 'pdl'})
    )
    
    # Pr√©paration pour la mise √† jour
    base_mise_a_jour = base.copy()
    
    # Mise √† jour
    base_mise_a_jour.update(relev√©s_trouv√©s)

    return base_mise_a_jour

def calculer_energies(
    base: DataFrame[BaseCalculEnergies],
    inclure_jour_fin: bool=False
) -> DataFrame[BaseCalculEnergies]:
    """
    ‚ö° Calcule les √©nergies consomm√©es en faisant la diff√©rence entre les index de fin et de d√©but
    pour les lignes o√π les calendriers de distribution sont identiques.

    Args:
        base (DataFrame[BaseCalculEnergies]): Base contenant les relev√©s de d√©but et de fin.

    Returns:
        DataFrame[BaseCalculEnergies]: Base avec les √©nergies calcul√©es.
    """
    # Liste des cadrans d'index √† traiter
    cadrans = ['HPH', 'HPB', 'HCH', 'HCB', 'HP', 'HC', 'BASE']
    
    # Copie de la base pour ne pas modifier l'original
    resultat = base.copy()
    
    # V√©rification de l'√©galit√© des calendriers distributeur
    calendriers_identiques = (
        resultat["Id_Calendrier_Distributeur_deb"] == 
        resultat["Id_Calendrier_Distributeur_fin"]
    )
    
    # On ne calcule les √©nergies que pour les lignes o√π les calendriers sont identiques
    lignes_valides = resultat[calendriers_identiques].index
    
    if len(lignes_valides) == 0:
        print("‚ö†Ô∏è Aucune ligne avec des calendriers identiques trouv√©e.")
        return resultat
    
    # Pour chaque cadran, calculer l'√©nergie consomm√©e
    for cadran in cadrans:
        col_deb = f"{cadran}_deb"
        col_fin = f"{cadran}_fin"
        col_energie = cadran
        
        # Calculer l'√©nergie comme la diff√©rence entre l'index de fin et de d√©but
        # On arrondit √† l'entier inf√©rieur pour √©viter les probl√®mes de pr√©cision diff√©rentes entre les relev√©s,
        resultat.loc[lignes_valides, col_energie] = (
            np.floor(resultat.loc[lignes_valides, col_fin]) - 
            np.floor(resultat.loc[lignes_valides, col_deb])
        )
        
        # V√©rifier les valeurs n√©gatives (anomalies potentielles)
        nb_negatifs = (resultat.loc[lignes_valides, col_energie] < 0).sum()
        if nb_negatifs > 0:
            print(f"‚ö†Ô∏è {nb_negatifs} valeurs n√©gatives d√©tect√©es pour {col_energie}")
    
    # Ajouter une colonne pour indiquer si l'√©nergie a √©t√© calcul√©e
    resultat["Energie_Calculee"] = False
    resultat.loc[lignes_valides, "Energie_Calculee"] = True
    
    # Calculer la somme totale des √©nergies (tous cadrans confondus)
        # Calcul du nombre de jours entre les deux relev√©s
    resultat['j'] = (
        resultat["Date_Releve_fin"].dt.date - resultat["Date_Releve_deb"].dt.date
    ).apply(lambda x: x.days + (1 if inclure_jour_fin else 0))

    # Calculer HP et HC en prenant la somme des colonnes correspondantes
    resultat['HP'] = resultat[['HPH', 'HPB', 'HP']].sum(axis=1, min_count=1)
    resultat['HC'] = resultat[['HCH', 'HCB', 'HC']].sum(axis=1, min_count=1)

    # Calculer BASE uniquement l√† o√π BASE est NaN
    resultat.loc[resultat['BASE'].isna(), 'BASE'] = resultat[['HP', 'HC']].sum(axis=1, min_count=1)
    
    return resultat


@pa.check_types
def extraire_releves_mensuels(relev√©s: DataFrame[Relev√©Index]) -> pd.DataFrame:
    """
    Extrait les relev√©s mensuels (premiers du mois) avec source et ordre_index.
    
    Args:
        relev√©s: DataFrame des relev√©s d'index
        
    Returns:
        DataFrame avec les relev√©s mensuels enrichis
    """
    rel_mensuels = relev√©s[relev√©s['Date_Releve'].dt.day == 1].copy()
    rel_mensuels['source'] = 'regular'
    rel_mensuels['ordre_index'] = 0
    
    return rel_mensuels


@curry
def combiner_releves_evenements(relev√©s: DataFrame[Relev√©Index],
                               evenements_impactants: DataFrame[HistoriqueP√©rim√®tre]) -> pd.DataFrame:
    """
    Combine les relev√©s d'√©v√©nements avec les relev√©s mensuels, g√©rant les doublons.
    
    Args:
        relev√©s: Relev√©s mensuels
        evenements_impactants: √âv√©nements ayant un impact sur l'√©nergie
        
    Returns:
        DataFrame combin√© sans doublons, prioris√© par source event
    """
    from electricore.core.p√©rim√®tre import extraire_releves_evenements
    
    # Extraire les relev√©s d'√©v√©nements
    rel_evenements = extraire_releves_evenements(evenements_impactants).copy()
    rel_evenements['source'] = 'event'
    
    # Extraire les relev√©s mensuels
    rel_mensuels = extraire_releves_mensuels(relev√©s)
    
    # Combiner avec gestion des doublons
    rel_combines = pd.concat([rel_evenements, rel_mensuels], ignore_index=True)
    rel_combines = rel_combines.sort_values(['pdl', 'Date_Releve', 'source']).reset_index(drop=True)
    
    # Supprimer les lignes regular quand il y a un event le m√™me jour
    duplicates_mask = rel_combines.duplicated(subset=['pdl', 'Date_Releve'], keep=False)
    mask_regular_to_remove = (
        duplicates_mask & 
        (rel_combines['source'] == 'regular') &
        rel_combines.groupby(['pdl', 'Date_Releve'])['source'].transform(lambda x: 'event' in x.values)
    )
    
    return rel_combines[~mask_regular_to_remove].reset_index(drop=True)


@curry
def generer_grille_facturation(rel_combines: pd.DataFrame) -> pd.DataFrame:
    """
    G√©n√®re la grille compl√®te de facturation mensuelle pour chaque PDL.
    
    Args:
        rel_combines: DataFrame des relev√©s combin√©s
        
    Returns:
        DataFrame avec grille compl√®te incluant points de facturation
    """
    # D√©terminer la p√©riode couverte pour chaque PDL
    pdl_periods = rel_combines.groupby('pdl')['Date_Releve'].agg(['min', 'max']).reset_index()
    
    # G√©n√©rer toutes les dates de premier du mois pour chaque PDL
    grille_facturation = []
    
    for _, row in pdl_periods.iterrows():
        pdl = row['pdl']
        start_date = row['min'].replace(day=1)  
        end_date = row['max'].replace(day=1)   
        
        # G√©n√©rer les premiers du mois entre start et end
        dates_facturation = pd.date_range(start=start_date, end=end_date, freq='MS')
        
        for date_fact in dates_facturation:
            grille_facturation.append({
                'pdl': pdl,
                'Date_Releve': date_fact,
                'source': 'facturation',
                'ordre_index': 0
            })
    
    grille_facturation_df = pd.DataFrame(grille_facturation)
    
    # Fusionner avec les relev√©s existants
    rel_complets = pd.merge(
        grille_facturation_df,
        rel_combines,
        on=['pdl', 'Date_Releve'],
        how='left',
        suffixes=('_grid', '_data')
    )
    
    # Nettoyer les colonnes
    cadrans = ['BASE', 'HP', 'HC', 'HPH', 'HPB', 'HCH', 'HCB']
    rel_complets['source'] = rel_complets['source_data'].fillna('facturation')
    rel_complets['ordre_index'] = rel_complets['ordre_index_data'].fillna(0)
    rel_complets['has_data'] = rel_complets['source_data'].notna()
    
    # Conserver les colonnes essentielles
    colonnes_finales = ['pdl', 'Date_Releve', 'source', 'ordre_index', 'has_data'] + \
                      [col for col in cadrans if col in rel_complets.columns]
    
    return rel_complets[colonnes_finales].sort_values(['pdl', 'Date_Releve', 'ordre_index']).reset_index(drop=True)


@pa.check_types
def calculer_periodes_energie(relev√©s_complets: pd.DataFrame) -> DataFrame[PeriodeEnergie]:
    """
    Calcule les p√©riodes d'√©nergie avec IDs et flags de qualit√© des donn√©es.
    
    Args:
        relev√©s_complets: DataFrame avec colonnes pdl, Date_Releve, source, has_data, cadrans
        
    Returns:
        DataFrame[PeriodeEnergie] avec p√©riodes d'√©nergie incluant les r√©f√©rences d'index
    """
    cadrans = ["BASE", "HP", "HC", "HPH", "HPB", "HCH", "HCB"]
    
    # Ajouter un ID temporaire pour chaque relev√©
    relev√©s = relev√©s_complets.copy()
    relev√©s = relev√©s.sort_values(['pdl', 'Date_Releve', 'ordre_index']).reset_index(drop=True)
    relev√©s['index_id'] = range(len(relev√©s))
    
    # Calculer les d√©calages pour les relev√©s pr√©c√©dents
    relev√©s_d√©cal√©s = relev√©s.groupby('pdl').shift(1)
    
    # Pr√©parer le r√©sultat
    r√©sultat = relev√©s.copy()
    r√©sultat['Date_Debut'] = relev√©s_d√©cal√©s['Date_Releve']
    r√©sultat['source_avant'] = relev√©s_d√©cal√©s['source']
    r√©sultat['has_data_avant'] = relev√©s_d√©cal√©s['has_data']
    r√©sultat['id_index_avant'] = relev√©s_d√©cal√©s['index_id']
    
    # Renommer pour clarifier
    r√©sultat = r√©sultat.rename(columns={
        'Date_Releve': 'Date_Fin',
        'source': 'source_apres',
        'has_data': 'has_data_apres',
        'index_id': 'id_index_apres'
    })
    
    # Calculer les √©nergies
    for cadran in cadrans:
        if cadran in relev√©s.columns:
            r√©sultat[f'{cadran}_energie'] = relev√©s[cadran] - relev√©s_d√©cal√©s[cadran]
        else:
            r√©sultat[f'{cadran}_energie'] = np.nan
    
    # Calculer les flags de qualit√©
    r√©sultat['data_complete'] = r√©sultat['has_data_avant'] & r√©sultat['has_data_apres']
    r√©sultat['duree_jours'] = (r√©sultat['Date_Fin'] - r√©sultat['Date_Debut']).dt.days
    r√©sultat['periode_irreguliere'] = r√©sultat['duree_jours'] > 35
    
    # Colonnes finales
    colonnes_energie = [f'{cadran}_energie' for cadran in cadrans if f'{cadran}_energie' in r√©sultat.columns]
    colonnes_finales = [
        'pdl', 'Date_Debut', 'Date_Fin', 'duree_jours',
        'id_index_avant', 'id_index_apres',
        'source_avant', 'source_apres', 
        'data_complete', 'periode_irreguliere'
    ] + colonnes_energie
    
    r√©sultat = r√©sultat[colonnes_finales]
    
    # Filtrer les lignes sans date de d√©but (premier relev√© de chaque PDL)
    r√©sultat = r√©sultat.dropna(subset=['Date_Debut'])
    
    # Filtrer les p√©riodes de dur√©e z√©ro
    r√©sultat = r√©sultat[r√©sultat['Date_Debut'] != r√©sultat['Date_Fin']]
    
    # Convertir les IDs en object pour pr√©server le type attendu par Pandera
    if not r√©sultat.empty:
        r√©sultat['id_index_avant'] = r√©sultat['id_index_avant'].astype('object')
        r√©sultat['id_index_apres'] = r√©sultat['id_index_apres'].astype('object')
    
    return r√©sultat.reset_index(drop=True)