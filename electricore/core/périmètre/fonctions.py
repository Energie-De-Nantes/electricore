import pandas as pd
import pandera.pandas as pa
from pandera.typing import DataFrame
from babel.dates import format_date

from electricore.core.p√©rim√®tre.mod√®les import HistoriqueP√©rim√®tre, SituationP√©rim√®tre, ModificationContractuelleImpactante
from electricore.core.relev√©s.mod√®les import Relev√©Index

@pa.check_types
def extraire_situation(date: pd.Timestamp, historique: DataFrame[HistoriqueP√©rim√®tre]) -> DataFrame[SituationP√©rim√®tre]:
    """
    Extrait la situation du p√©rim√®tre √† une date donn√©e.
    
    Args:
        date (pd.Timestamp): La date de r√©f√©rence.
        historique (pd.DataFrame): L'historique des √©v√©nements contractuels.

    Returns:
        pd.DataFrame: Une vue du p√©rim√®tre √† `date`, conforme √† `SituationP√©rim√®tre`.
    """
    return (
        historique[historique["Date_Evenement"] <= date]
        .sort_values(by="Date_Evenement", ascending=False)
        .drop_duplicates(subset=["Ref_Situation_Contractuelle"], keep="first")
    )
@pa.check_types
def extraire_historique_√†_date(
    historique: DataFrame[HistoriqueP√©rim√®tre],
    fin: pd.Timestamp
) -> DataFrame[HistoriqueP√©rim√®tre]:
    """
    Extrait uniquement les variations (changements contractuels) qui ont eu lieu dans une p√©riode donn√©e.

    Args:
        deb (pd.Timestamp): D√©but de la p√©riode.
        fin (pd.Timestamp): Fin de la p√©riode.
        historique (pd.DataFrame): Historique des √©v√©nements contractuels.

    Returns:
        pd.DataFrame: Un sous-ensemble de l'historique contenant uniquement les variations dans la p√©riode.
    """
    return historique[
        (historique["Date_Evenement"] <= fin)
    ].sort_values(by="Date_Evenement", ascending=True)  # Trie par ordre chronologique

@pa.check_types
def extraire_p√©riode(
    deb: pd.Timestamp, fin: pd.Timestamp, 
    historique: DataFrame[HistoriqueP√©rim√®tre]
) -> DataFrame[HistoriqueP√©rim√®tre]:
    """
    Extrait uniquement les variations (changements contractuels) qui ont eu lieu dans une p√©riode donn√©e.

    Args:
        deb (pd.Timestamp): D√©but de la p√©riode.
        fin (pd.Timestamp): Fin de la p√©riode.
        historique (pd.DataFrame): Historique des √©v√©nements contractuels.

    Returns:
        pd.DataFrame: Un sous-ensemble de l'historique contenant uniquement les variations dans la p√©riode.
    """
    return historique[
        (historique["Date_Evenement"] >= deb) & (historique["Date_Evenement"] <= fin)
    ].sort_values(by="Date_Evenement", ascending=True)  # Trie par ordre chronologique

@pa.check_types
def extraite_relev√©s_entr√©es(
    historique: DataFrame[HistoriqueP√©rim√®tre]
) -> DataFrame[Relev√©Index]:
        _√©v√©nements = ['MES', 'PMES', 'CFNE']
        _colonnes_meta_releve = ['Ref_Situation_Contractuelle', 'pdl', 'Unit√©', 'Pr√©cision', 'Source']
        _colonnes_relev√© = ['Id_Calendrier_Distributeur', 'Date_Releve', 'Nature_Index', 'HP', 'HC', 'HCH', 'HPH', 'HPB', 'HCB', 'BASE']
        _colonnes_relev√©_apr√®s = ['Apr√®s_'+c for c in _colonnes_relev√©]
        return Relev√©Index.validate(
            historique[historique['Evenement_Declencheur'].isin(_√©v√©nements)][_colonnes_meta_releve + _colonnes_relev√©_apr√®s]
            .rename(columns={k: v for k,v in zip(_colonnes_relev√©_apr√®s, _colonnes_relev√©)})
            .dropna(subset=['Date_Releve'])
            )

@pa.check_types
def extraite_relev√©s_sorties(
    historique: DataFrame[HistoriqueP√©rim√®tre]
) -> DataFrame[Relev√©Index]:
        _√©v√©nements = ['RES', 'CFNS']
        _colonnes_meta_releve = ['Ref_Situation_Contractuelle', 'pdl', 'Unit√©', 'Pr√©cision', 'Source']
        _colonnes_relev√© = ['Id_Calendrier_Distributeur', 'Date_Releve', 'Nature_Index', 'HP', 'HC', 'HCH', 'HPH', 'HPB', 'HCB', 'BASE']
        _colonnes_relev√©_avant = ['Avant_'+c for c in _colonnes_relev√©]
        return Relev√©Index.validate(
            historique[historique['Evenement_Declencheur'].isin(_√©v√©nements)][_colonnes_meta_releve + _colonnes_relev√©_avant]
            .rename(columns={k: v for k,v in zip(_colonnes_relev√©_avant, _colonnes_relev√©)})
            .dropna(subset=['Date_Releve'])
            )

@pa.check_types
def extraire_modifications_impactantes(
    deb: pd.Timestamp,
    historique: DataFrame[HistoriqueP√©rim√®tre]
) -> DataFrame[ModificationContractuelleImpactante]:
    """
    D√©tecte les MCT dans une p√©riode donn√©e et renvoie les variations de Puissance_Souscrite
    et Formule_Tarifaire_Acheminement avant et apr√®s chaque MCT.

    Args:
        deb (pd.Timestamp): D√©but de la p√©riode.
        historique (pd.DataFrame): Historique des √©v√©nements contractuels.

    Returns:
        DataFrame[ModificationContractuelleImpactante]: DataFrame contenant les MCT avec les valeurs avant/apr√®s.
    """

    # üîç D√©caler les valeurs pour obtenir les donn√©es "avant" AVANT de filtrer
    historique = historique.sort_values(by=["Ref_Situation_Contractuelle", "Date_Evenement"])
    historique["Avant_Puissance_Souscrite"] = historique.groupby("Ref_Situation_Contractuelle")["Puissance_Souscrite"].shift(1)
    historique["Avant_Formule_Tarifaire_Acheminement"] = historique.groupby("Ref_Situation_Contractuelle")["Formule_Tarifaire_Acheminement"].shift(1)


    # üìå Filtrer uniquement les MCT dans la p√©riode donn√©e
    impacts = (
          historique[
            (historique["Date_Evenement"] >= deb) &
            (historique["Evenement_Declencheur"] == "MCT")]
          .copy()
          .rename(columns={'Puissance_Souscrite': 'Apr√®s_Puissance_Souscrite', 'Formule_Tarifaire_Acheminement':'Apr√®s_Formule_Tarifaire_Acheminement'})
          .drop(columns=['Segment_Clientele', 'Num_Depannage', 'Categorie', 'Etat_Contractuel', 'Type_Compteur', 'Date_Derniere_Modification_FTA', 'Type_Evenement', 'Ref_Demandeur', 'Id_Affaire'])
    )
    
    # TODO: Prendre en compte plus de cas
    impacts['Impacte_energies'] = (
        impacts["Avant_Id_Calendrier_Distributeur"].notna() & 
        impacts["Apr√®s_Id_Calendrier_Distributeur"].notna() & 
        (impacts["Avant_Id_Calendrier_Distributeur"] != impacts["Apr√®s_Id_Calendrier_Distributeur"])
    )

    # ‚ûï Ajout de la colonne de lisibilit√© du changement
    def generer_resum√©(row):
        modifications = []
        if row["Avant_Puissance_Souscrite"] != row["Apr√®s_Puissance_Souscrite"]:
            modifications.append(f"P: {row['Avant_Puissance_Souscrite']} ‚Üí {row['Apr√®s_Puissance_Souscrite']}")
        if row["Avant_Formule_Tarifaire_Acheminement"] != row["Apr√®s_Formule_Tarifaire_Acheminement"]:
            modifications.append(f"FTA: {row['Avant_Formule_Tarifaire_Acheminement']} ‚Üí {row['Apr√®s_Formule_Tarifaire_Acheminement']}")
        return ", ".join(modifications) if modifications else "Aucun changement"
    
    impacts["R√©sum√©_Modification"] = impacts.apply(generer_resum√©, axis=1)

    ordre_colonnes = ModificationContractuelleImpactante.to_schema().columns.keys()
    impacts = impacts[ordre_colonnes]
    
    return impacts

@pa.check_types
def detecter_points_de_rupture(historique: DataFrame[HistoriqueP√©rim√®tre]) -> DataFrame[HistoriqueP√©rim√®tre]:
    """
    Enrichit l'historique avec les colonnes d'impact (turpe, √©nergie, turpe_variable) et un r√©sum√© des modifications.
    Toutes les lignes sont conserv√©es.

    Args:
        historique (pd.DataFrame): Historique complet des √©v√©nements contractuels.

    Returns:
        pd.DataFrame: Historique enrichi avec d√©tection des ruptures et r√©sum√© humain.
    """
    index_cols = ['BASE', 'HP', 'HC', 'HPH', 'HCH', 'HPB', 'HCB']

    historique = historique.sort_values(by=["Ref_Situation_Contractuelle", "Date_Evenement"]).copy()
    historique["Avant_Puissance_Souscrite"] = historique.groupby("Ref_Situation_Contractuelle")["Puissance_Souscrite"].shift(1)
    historique["Avant_Formule_Tarifaire_Acheminement"] = historique.groupby("Ref_Situation_Contractuelle")["Formule_Tarifaire_Acheminement"].shift(1)

    impact_turpe_fixe = (
        (historique["Avant_Puissance_Souscrite"].notna() &
         (historique["Avant_Puissance_Souscrite"] != historique["Puissance_Souscrite"])) |
        (historique["Avant_Formule_Tarifaire_Acheminement"].notna() &
         (historique["Avant_Formule_Tarifaire_Acheminement"] != historique["Formule_Tarifaire_Acheminement"]))
    )
    
    changement_calendrier = (
        historique["Avant_Id_Calendrier_Distributeur"].notna() &
        historique["Apr√®s_Id_Calendrier_Distributeur"].notna() &
        (historique["Avant_Id_Calendrier_Distributeur"] != historique["Apr√®s_Id_Calendrier_Distributeur"])
    )
    
    changement_index = pd.concat([
        (historique[f"Avant_{col}"].notna() &
         historique[f"Apr√®s_{col}"].notna() &
         (historique[f"Avant_{col}"] != historique[f"Apr√®s_{col}"]))
        for col in index_cols
    ], axis=1).any(axis=1)

    impact_energie = changement_calendrier | changement_index

    impact_turpe_variable = (
      (impact_energie) |
      (historique["Avant_Formule_Tarifaire_Acheminement"].notna() &
         (historique["Avant_Formule_Tarifaire_Acheminement"] != historique["Formule_Tarifaire_Acheminement"]))
    )

    historique["impact_turpe_fixe"] = impact_turpe_fixe
    historique["impact_energie"] = impact_energie
    historique["impact_turpe_variable"] = impact_turpe_variable

    # Forcer les impacts √† True pour les √©v√©nements d‚Äôentr√©e et de sortie
    evenements_entree_sortie = ["CFNE", "MES", "PMES", "CFNS", "RES"]
    mask_entree_sortie = historique["Evenement_Declencheur"].isin(evenements_entree_sortie)

    historique.loc[mask_entree_sortie, ["impact_turpe_fixe", "impact_energie", "impact_turpe_variable"]] = True

    def generer_resume(row):
        modifs = []
        if row["impact_turpe_fixe"]:
            if pd.notna(row.get("Avant_Puissance_Souscrite")) and row["Avant_Puissance_Souscrite"] != row["Puissance_Souscrite"]:
                modifs.append(f"P: {row['Avant_Puissance_Souscrite']} ‚Üí {row['Puissance_Souscrite']}")
            if pd.notna(row.get("Avant_Formule_Tarifaire_Acheminement")) and row["Avant_Formule_Tarifaire_Acheminement"] != row["Formule_Tarifaire_Acheminement"]:
                modifs.append(f"FTA: {row['Avant_Formule_Tarifaire_Acheminement']} ‚Üí {row['Formule_Tarifaire_Acheminement']}")
        if row["impact_energie"]:
            modifs.append("rupture index")
        if changement_calendrier.loc[row.name]:
            modifs.append(f"Cal: {row['Avant_Id_Calendrier_Distributeur']} ‚Üí {row['Apr√®s_Id_Calendrier_Distributeur']}")
        return ", ".join(modifs) if modifs else ""

    historique["resume_modification"] = historique.apply(generer_resume, axis=1)

    return historique.reset_index(drop=True)




@pa.check_types
def inserer_evenements_facturation(historique: DataFrame[HistoriqueP√©rim√®tre]) -> DataFrame[HistoriqueP√©rim√®tre]:
    """
    Ins√®re des √©v√©nements de facturation artificielle au 1er de chaque mois.
    
    Cette fonction g√©n√®re des √©v√©nements "FACTURATION" pour permettre un calcul mensuel
    des abonnements. Elle traite chaque PDL individuellement selon sa p√©riode d'activit√©.
    
    LOGIQUE GLOBALE :
    1. D√©tecter les p√©riodes d'activit√© de chaque PDL (entr√©e ‚Üí sortie)
    2. G√©n√©rer tous les 1ers du mois dans la plage globale
    3. Associer chaque PDL aux mois o√π il est actif
    4. Cr√©er les √©v√©nements artificiels et propager les donn√©es contractuelles
    
    Args:
        historique: DataFrame contenant l'historique des √©v√©nements contractuels
        
    Returns:
        DataFrame √©tendu avec les √©v√©nements de facturation artificiels
    """
    tz = "Europe/Paris"

    # =============================================================================
    # √âTAPE 1 : D√âTECTION DES P√âRIODES D'ACTIVIT√â (INDIVIDUALIS√â PAR PDL)
    # =============================================================================
    
    # 1A. Identifier les dates d'entr√©e de chaque PDL
    print("üîç D√©tection des entr√©es...")
    entrees = historique[historique['Evenement_Declencheur'].isin(['CFNE', 'MES', 'PMES'])]
    debuts = entrees.groupby('Ref_Situation_Contractuelle')['Date_Evenement'].min()
    print(f"   - {len(entrees)} √©v√©nements d'entr√©e pour {len(debuts)} PDL")
    
    # 1B. Identifier les dates de sortie de chaque PDL
    print("üîç D√©tection des sorties...")
    sorties = historique[historique['Evenement_Declencheur'].isin(['RES', 'CFNS'])]
    fins = sorties.groupby('Ref_Situation_Contractuelle')['Date_Evenement'].max()
    print(f"   - {len(sorties)} √©v√©nements de sortie pour {len(fins)} PDL")
    
    # 1C. D√©finir la date limite pour les PDL non r√©sili√©s
    # LOGIQUE : g√©n√®re des √©v√©nements jusqu'au d√©but du mois courant inclus
    fin_par_defaut = pd.Timestamp.now(tz=tz).to_period("M").start_time.tz_localize(tz)
    print(f"   - Date limite pour PDL actifs : {fin_par_defaut}")
    
    # 1D. Construire le DataFrame des p√©riodes individuelles
    periodes = pd.DataFrame({
        "start": debuts,
        "end": fins
    }).fillna(fin_par_defaut)
    
    print(f"üìä P√©riodes d'activit√© :")
    print(f"   - Total PDL : {len(periodes)}")
    print(f"   - PDL r√©sili√©s : {periodes['end'].notna().sum() - (periodes['end'] == fin_par_defaut).sum()}")
    print(f"   - PDL actifs : {(periodes['end'] == fin_par_defaut).sum()}")

    # 1E. Filtrer les PDL entr√©s apr√®s la date limite (pas d'√©v√©nements pour ces PDL)
    # LOGIQUE : Un PDL entr√© apr√®s le 1er du mois courant ne g√©n√®re pas d'√©v√©nements pour ce mois
    periodes_valides = periodes[periodes["start"] <= periodes["end"]]
    periodes_invalides = periodes[periodes["start"] > periodes["end"]]
    
    if len(periodes_invalides) > 0:
        print(f"‚ö†Ô∏è  PDL entr√©s trop tard (apr√®s {fin_par_defaut.strftime('%Y-%m-%d')}) : {len(periodes_invalides)}")
        for ref, row in periodes_invalides.iterrows():
            print(f"   - {ref}: entr√©e le {row['start'].strftime('%Y-%m-%d')} (exclu)")
    
    if len(periodes_valides) == 0:
        print("‚ùå Aucun PDL n'a de p√©riode valide pour g√©n√©rer des √©v√©nements")
        return historique  # Retourner l'historique original sans modification
    
    print(f"   - PDL avec p√©riodes valides : {len(periodes_valides)}")

    # =============================================================================
    # √âTAPE 2 : G√âN√âRATION DES DATES MENSUELLES (GLOBAL)
    # =============================================================================
    
    # 2A. Calculer la plage globale de dates (uniquement pour les PDL valides)
    min_date = periodes_valides["start"].min()
    max_date = periodes_valides["end"].max()
    print(f"üóìÔ∏è  Plage globale : {min_date} ‚Üí {max_date}")
    
    # 2B. G√©n√©rer tous les 1ers du mois dans cette plage (inclus)
    # ASTUCE : ajouter 1 jour √† max_date pour √™tre s√ªr d'inclure le mois de fin
    max_date_inclusive = max_date + pd.DateOffset(days=1)
    all_months = pd.date_range(start=min_date, end=max_date_inclusive, freq="MS", tz=tz)
    print(f"   - {len(all_months)} mois g√©n√©r√©s de {all_months[0].strftime('%Y-%m')} √† {all_months[-1].strftime('%Y-%m')}")
    
    # =============================================================================
    # √âTAPE 3 : ASSOCIATION PDL ‚Üî MOIS (INDIVIDUALIS√â PAR PDL)
    # =============================================================================
    
    # 3A. Faire un produit cart√©sien : chaque PDL valide √ó chaque mois
    print("üîó Association PDL ‚Üî mois...")
    ref_mois = (
        periodes_valides.reset_index()
        .merge(pd.DataFrame({"Date_Evenement": all_months}), how="cross")
    )
    
    # 3A bis. Ajouter le mapping Ref_Situation_Contractuelle ‚Üí pdl depuis l'historique
    mapping_pdl = historique[['Ref_Situation_Contractuelle', 'pdl']].drop_duplicates()
    ref_mois = ref_mois.merge(mapping_pdl, on='Ref_Situation_Contractuelle', how='left')
    
    print(f"   - {len(ref_mois)} combinaisons PDL√ómois avant filtrage")
    
    # 3B. Filtrer pour ne garder que les mois o√π chaque PDL est actif
    # CORRECTION : comparer les dates, pas les timestamps avec heures
    # Car les √©v√©nements FACTURATION sont g√©n√©r√©s avec freq="MS" (d√©but de mois avec heure)
    # alors que fin_par_defaut est √† 00:00:00
    # IMPORTANT : pour √©viter les conflits avec ffill, exclure le mois d'entr√©e
    ref_mois = ref_mois[
        (ref_mois["Date_Evenement"].dt.date > ref_mois["start"].dt.date) & 
        (ref_mois["Date_Evenement"].dt.date <= ref_mois["end"].dt.date)
    ]
    print(f"   - {len(ref_mois)} combinaisons PDL√ómois apr√®s filtrage")
    
    # 3C. Statistiques de r√©partition
    events_par_pdl = ref_mois.groupby('Ref_Situation_Contractuelle').size()
    print(f"   - Moyenne : {events_par_pdl.mean():.1f} √©v√©nements/PDL")
    print(f"   - Min/Max : {events_par_pdl.min()}/{events_par_pdl.max()} √©v√©nements/PDL")

    # =============================================================================
    # √âTAPE 4 : CR√âATION DES √âV√âNEMENTS ARTIFICIELS (GLOBAL)
    # =============================================================================
    
    # 4A. Cr√©er les √©v√©nements de facturation
    print("üìÖ Cr√©ation des √©v√©nements artificiels...")
    evenements = ref_mois.copy()
    evenements["Evenement_Declencheur"] = "FACTURATION"
    evenements["Type_Evenement"] = "artificiel"
    evenements["Source"] = "synthese_mensuelle"
    evenements["resume_modification"] = "Facturation mensuelle"
    evenements["impact_turpe_fixe"] = True
    evenements["impact_energie"] = True
    evenements["impact_turpe_variable"] = True

    # 4B. S√©lectionner les colonnes n√©cessaires (inclure pdl pour √©viter les NaN)
    evenements = evenements[[
        "Ref_Situation_Contractuelle", "pdl", "Date_Evenement",
        "Evenement_Declencheur", "Type_Evenement", "Source", "resume_modification",
        "impact_turpe_fixe", "impact_energie", "impact_turpe_variable"
    ]]
    print(f"   - {len(evenements)} √©v√©nements de facturation cr√©√©s")

    # =============================================================================
    # √âTAPE 5 : PROPAGATION DES DONN√âES CONTRACTUELLES (INDIVIDUALIS√â PAR PDL)
    # =============================================================================
    
    # 5A. Fusionner historique original + √©v√©nements artificiels
    print("üîÑ Propagation des donn√©es contractuelles...")
    fusion = pd.concat([historique, evenements], ignore_index=True).sort_values(
        ["Ref_Situation_Contractuelle", "Date_Evenement"]
    ).reset_index(drop=True)
    
    # 5B. Identifier les colonnes √† propager (non-nullables du mod√®le Pandera)
    # Ensure the schema is populated to access field information
    schema = HistoriqueP√©rim√®tre.to_schema()
    colonnes_ffill = [
        name for name, col_info in schema.columns.items()
        if name in fusion.columns and not col_info.nullable
    ]
    print(f"   - {len(colonnes_ffill)} colonnes √† propager : {colonnes_ffill}")

    # 5C. Propager les donn√©es par PDL avec forward fill
    # LOGIQUE : chaque √©v√©nement artificiel h√©rite des caract√©ristiques du dernier √©v√©nement r√©el
    fusion[colonnes_ffill] = (
        fusion.groupby("Ref_Situation_Contractuelle")[colonnes_ffill]
        .ffill()
    )

    # =============================================================================
    # √âTAPE 6 : EXTRACTION ET ASSEMBLAGE FINAL (GLOBAL)
    # =============================================================================
    
    # 6A. Extraire uniquement les √©v√©nements FACTURATION avec donn√©es propag√©es
    ajout = fusion[fusion["Evenement_Declencheur"] == "FACTURATION"]
    print(f"   - {len(ajout)} √©v√©nements FACTURATION avec donn√©es propag√©es")

    # 6B. Assemblage final : historique original + √©v√©nements artificiels
    historique_etendu = pd.concat([historique, ajout], ignore_index=True).sort_values(
        ["Ref_Situation_Contractuelle", "Date_Evenement"]
    ).reset_index(drop=True)
    
    print(f"‚úÖ Historique √©tendu : {len(historique_etendu)} √©v√©nements total")
    print(f"   - √âv√©nements originaux : {len(historique)}")
    print(f"   - √âv√©nements artificiels : {len(ajout)}")
    
    return historique_etendu

@pa.check_types
def extraire_releves_evenements(historique: DataFrame[HistoriqueP√©rim√®tre]) -> DataFrame[Relev√©Index]:
    """
    G√©n√®re des relev√©s d'index (avant/apr√®s) √† partir d'un historique enrichi des √©v√©nements contractuels.

    - Un relev√© "avant" (ordre_index=0) est cr√©√© √† partir des index Avant_*
    - Un relev√© "apr√®s" (ordre_index=1) est cr√©√© √† partir des index Apr√®s_*
    - La colonne 'ordre_index' permet de trier correctement les relev√©s successifs.

    Args:
        historique (pd.DataFrame): Historique enrichi (HistoriqueP√©rim√®tre√âtendu).

    Returns:
        pd.DataFrame: Relev√©s d‚Äôindex conformes au mod√®le Relev√©Index.
    """
    index_cols = ["BASE", "HP", "HC", "HCH", "HPH", "HPB", "HCB", "Id_Calendrier_Distributeur"]
    identifiants = ["pdl", "Ref_Situation_Contractuelle", "Formule_Tarifaire_Acheminement"]

    # Cr√©er relev√©s "avant"
    avant = historique[identifiants + ["Date_Evenement"] + [f"Avant_{col}" for col in index_cols]].copy()
    avant = avant.rename(columns={f"Avant_{col}": col for col in index_cols})
    avant["ordre_index"] = 0

    # Cr√©er relev√©s "apr√®s"
    apres = historique[identifiants + ["Date_Evenement"] + [f"Apr√®s_{col}" for col in index_cols]].copy()
    apres = apres.rename(columns={f"Apr√®s_{col}": col for col in index_cols})
    apres["ordre_index"] = 1

    # Concat√©ner
    resultats = pd.concat([avant, apres], ignore_index=True)
    resultats = resultats.dropna(subset=index_cols, how="all")
    resultats["Source"] = "flux_C15"
    resultats["Unit√©"] = "kWh" 
    resultats["Pr√©cision"] = "kWh"

    resultats = resultats.rename(columns={"Date_Evenement": "Date_Releve"})

    # R√©ordonner selon mod√®le Relev√©Index (on ne garde que les colonnes pr√©sentes)
    colonnes_finales = [col for col in Relev√©Index.to_schema().columns.keys() if col in resultats.columns]
    resultats = resultats[colonnes_finales]

    return resultats


@pa.check_types
def enrichir_historique_p√©rim√®tre(historique: DataFrame[HistoriqueP√©rim√®tre]) -> DataFrame[HistoriqueP√©rim√®tre]:
    """
    Enrichit l'historique du p√©rim√®tre avec les points de rupture et les √©v√©nements de facturation.
    
    Cette fonction combine deux traitements essentiels sur l'historique du p√©rim√®tre :
    1. D√©tection des points de rupture (changements de p√©riodes)
    2. Insertion des √©v√©nements de facturation synth√©tiques (1er du mois)
    
    Utilis√©e comme √©tape pr√©paratoire dans les pipelines de calcul d'abonnements et d'√©nergies.
    
    Args:
        historique: Historique des √©v√©nements contractuels du p√©rim√®tre
        
    Returns:
        DataFrame enrichi avec points de rupture d√©tect√©s et √©v√©nements de facturation
    """
    return (
        historique
        .pipe(detecter_points_de_rupture)
        .pipe(inserer_evenements_facturation)
    )